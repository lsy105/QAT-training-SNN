{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polish-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import time\n",
    "import h5py\n",
    "import sys\n",
    "from dataset import Dataset, SpikingDataset, SpikingMNISTDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "torch.__version__\n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) \n",
    "\n",
    "print(\"init done\")\n",
    "\n",
    "#The class is based on the code in: https://github.com/fzenke/spytorch.git\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    scale = 100.0\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "spike_fn  = SurrGradSpike.apply\n",
    "\n",
    "class FakeQuantize(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, in_data, num_bits, scale):\n",
    "        #if min_data is None or max_data is None:\n",
    "        min_data, max_data = torch.min(in_data), torch.max(in_data)\n",
    "        upper = torch.max(torch.abs(min_data), torch.abs(max_data))\n",
    "        lower = torch.min(torch.abs(min_data), torch.abs(max_data))\n",
    "        qmin = 0\n",
    "        qmax = 2**num_bits - 1 \n",
    "        length = upper #+ torch.FloatTensor(1,).uniform_(-0.05*upper, 0.05*upper).to(device)\n",
    "        scale[0] = length / (qmax - qmin)\n",
    "        #new_data = torch.clamp(in_data, min=min_data.item(), max=max_data.item())\n",
    "        output = torch.round(in_data / scale[0]) \n",
    "        output = torch.clamp(output, min=-255, max=255)\n",
    "        output = output * scale[0]\n",
    "        #output = torch.round((new_data - min_data) / scale) * scale  + min_data\n",
    "        #output = torch.clamp(output, min=min_data.item(), max=max_data.item())\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None, None, None\n",
    "q_fn = FakeQuantize.apply\n",
    "\n",
    "class QLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=False, num_bits=8):\n",
    "        super(QLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.num_bits = num_bits\n",
    "        self.scale = [1.0]\n",
    "        \n",
    "    def forward(self, x, q=False):\n",
    "        if q:\n",
    "            W = q_fn(self.weight, self.num_bits, self.scale)\n",
    "            output = F.linear(x, W)\n",
    "        else:\n",
    "            output = F.linear(x, self.weight)\n",
    "            self.scale[0] = torch.ones([1], dtype=torch.float32, device=device)\n",
    "        return output, self.scale[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#The class is based on the code in: https://github.com/fzenke/spytorch.git\n",
    "def Recurrent(h1, nb_hidden, nb_steps, scale):\n",
    "    batch_size = h1.shape[0]\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=h1.device)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=h1.device)\n",
    "\n",
    "    mem_rec = [mem]\n",
    "    spk_rec = [mem]\n",
    "\n",
    "    for t in range(nb_steps):\n",
    "        #mthr = mem-np.rint(1.0 / scale.cpu().item()) * scale.cpu().item()\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = torch.zeros_like(mem)\n",
    "        c   = (mthr > 0)\n",
    "        rst[c] = torch.ones_like(mem)[c]\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = beta*mem +syn -rst\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    return spk_rec\n",
    "\n",
    "#The class is based on the code in: https://github.com/fzenke/spytorch.git\n",
    "def Readout(h2, nb_outputs):\n",
    "    # Readout layer\n",
    "    batch_size = h2.shape[0]\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=h2.device)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=h2.device)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    #other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec  #, other_recs\n",
    "\n",
    "class SpikingDenseNet(nn.Module):\n",
    "    def __init__(self, input_size, nb_steps, num_output, num_h):\n",
    "        super(SpikingDenseNet, self).__init__()\n",
    "        self.fc1 = QLinear(input_size, num_h, bias=False, num_bits=8)\n",
    "        self.fc2 = QLinear(num_h, num_h, bias=False, num_bits=8)\n",
    "        self.fc3 = QLinear(num_h, num_output, bias=False, num_bits=8)\n",
    "        self.num_h1 = num_h\n",
    "        self.num_h2 = num_h\n",
    "        self.num_output = num_output\n",
    "        self.nb_steps = nb_steps\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            n = 3\n",
    "            vec = [False for _ in range(n)]\n",
    "            idx = np.random.randint(low=0, high=n)\n",
    "            vec[idx] = True\n",
    "            #print(idx)\n",
    "        else:\n",
    "            vec = [False for _ in range(n)]\n",
    "        x, scale = self.fc1(x, vec[0])\n",
    "        x = Recurrent(x, self.num_h1, self.nb_steps, scale)\n",
    "        x, scale = self.fc2(x, vec[1])\n",
    "        x = Recurrent(x, self.num_h2, self.nb_steps, scale)\n",
    "        x, scale = self.fc3(x, vec[2])\n",
    "        x = Readout(x, self.num_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suitable-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, testloader, model, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        t0 = time.time()\n",
    "        for x_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            y_local = y_local.long().to(device)\n",
    "            #print(x_local.shape, y_local.shape)\n",
    "            output = model(x_local)\n",
    "            m,_=torch.max(output,1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        t1 = time.time()\n",
    "        print(t1 - t0)\n",
    "        print(\"epoch: %d\", e)\n",
    "        if e % 30 == 0:\n",
    "            print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(trainloader, net, \"train\")))\n",
    "            print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "def Extract(x, y, res, label):\n",
    "    x = x.cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "    batch_size, time_step, inputs = x.shape\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        for j in range(inputs):\n",
    "            res[j].append(np.nonzero(x[i, :, j])[0])\n",
    "        label.append(y[i])\n",
    "    \n",
    "def compute_classification_accuracy(dataloader, model, name):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    num_input = 28 * 28 * 1\n",
    "    res, label = [[] for _ in range(num_input)], []\n",
    "    for x_local, y_local in dataloader:\n",
    "        x_local = x_local.float().to(device)\n",
    "        y_local = y_local.long().to(device)\n",
    "        #Extract(x_local, y_local, res, label)\n",
    "        output = model(x_local)\n",
    "        m,_= torch.max(output,1) # max over time\n",
    "        _,am=torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    #with h5py.File('test.hdf5', 'w') as f: \n",
    "    #    f.create_dataset(\"data\", data = np.array(res).astype(np.float32))\n",
    "    #    f.create_dataset(\"label\", data = np.array(label).astype(np.float32))\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rubber-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "def GetMNIST():\n",
    "    import tensorflow as tf\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "  \n",
    "    #scale input data to 0 and 1\n",
    "    image_size = 28 * 28 * 1\n",
    "    x_train = x_train.reshape(-1, image_size).astype(np.float32) / 255.0\n",
    "    x_test = x_test.reshape(-1, image_size).astype(np.float32) / 255.0\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    #label to one_hot label\n",
    "    def one_hot(label, classes):\n",
    "        row = label.shape[0]\n",
    "        one_hot_label = np.zeros((row, classes))\n",
    "        one_hot_label[np.arange(row), label] = 1\n",
    "        return one_hot_label\n",
    "        y_train = one_hot(y_train.flatten(), 10)\n",
    "        y_test = one_hot(y_test.flatten(), 10)\n",
    "    \"\"\"\n",
    "x_train, y_train, x_test, y_test = GetMNIST()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hazardous-revolution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.00795841217041\n",
      "epoch: %d 0\n",
      "Training accuracy: 0.430\n",
      "Test accuracy: 0.433\n",
      "128.59041666984558\n",
      "epoch: %d 1\n",
      "128.63519740104675\n",
      "epoch: %d 2\n",
      "127.83162713050842\n",
      "epoch: %d 3\n",
      "128.08943629264832\n",
      "epoch: %d 4\n",
      "128.95740628242493\n",
      "epoch: %d 5\n",
      "129.44070982933044\n",
      "epoch: %d 6\n",
      "128.50268268585205\n",
      "epoch: %d 7\n",
      "128.65231370925903\n",
      "epoch: %d 8\n",
      "127.91505336761475\n",
      "epoch: %d 9\n",
      "127.86331057548523\n",
      "epoch: %d 10\n",
      "128.37370944023132\n",
      "epoch: %d 11\n",
      "128.77973818778992\n",
      "epoch: %d 12\n",
      "128.64366841316223\n",
      "epoch: %d 13\n",
      "127.42506122589111\n",
      "epoch: %d 14\n",
      "127.74420237541199\n",
      "epoch: %d 15\n",
      "127.83533644676208\n",
      "epoch: %d 16\n",
      "128.3978168964386\n",
      "epoch: %d 17\n",
      "129.07325911521912\n",
      "epoch: %d 18\n",
      "128.74108982086182\n",
      "epoch: %d 19\n",
      "130.00708961486816\n",
      "epoch: %d 20\n",
      "129.51887917518616\n",
      "epoch: %d 21\n",
      "127.26081085205078\n",
      "epoch: %d 22\n",
      "128.32207345962524\n",
      "epoch: %d 23\n",
      "128.65867161750793\n",
      "epoch: %d 24\n",
      "129.85766983032227\n",
      "epoch: %d 25\n",
      "127.5685362815857\n",
      "epoch: %d 26\n",
      "128.26856684684753\n",
      "epoch: %d 27\n",
      "127.74617958068848\n",
      "epoch: %d 28\n",
      "128.88242864608765\n",
      "epoch: %d 29\n",
      "129.35299801826477\n",
      "epoch: %d 30\n",
      "Training accuracy: 0.969\n",
      "Test accuracy: 0.955\n",
      "126.63282585144043\n",
      "epoch: %d 31\n",
      "128.47471356391907\n",
      "epoch: %d 32\n",
      "127.81045770645142\n",
      "epoch: %d 33\n",
      "129.25601935386658\n",
      "epoch: %d 34\n",
      "128.9632658958435\n",
      "epoch: %d 35\n",
      "128.8989119529724\n",
      "epoch: %d 36\n",
      "128.8706340789795\n",
      "epoch: %d 37\n",
      "127.87532496452332\n",
      "epoch: %d 38\n",
      "128.21611785888672\n",
      "epoch: %d 39\n",
      "128.5211477279663\n",
      "epoch: %d 40\n",
      "128.13691425323486\n",
      "epoch: %d 41\n",
      "128.2469220161438\n",
      "epoch: %d 42\n",
      "127.98241686820984\n",
      "epoch: %d 43\n",
      "128.59846591949463\n",
      "epoch: %d 44\n",
      "129.0412163734436\n",
      "epoch: %d 45\n",
      "128.45376014709473\n",
      "epoch: %d 46\n",
      "128.6874921321869\n",
      "epoch: %d 47\n",
      "127.29608702659607\n",
      "epoch: %d 48\n",
      "128.79809856414795\n",
      "epoch: %d 49\n",
      "128.34021067619324\n",
      "epoch: %d 50\n",
      "128.78467416763306\n",
      "epoch: %d 51\n",
      "128.2067267894745\n",
      "epoch: %d 52\n",
      "127.7886700630188\n",
      "epoch: %d 53\n",
      "128.83068299293518\n",
      "epoch: %d 54\n",
      "129.1404368877411\n",
      "epoch: %d 55\n",
      "128.04969549179077\n",
      "epoch: %d 56\n",
      "128.80227971076965\n",
      "epoch: %d 57\n",
      "128.3125352859497\n",
      "epoch: %d 58\n",
      "128.9569537639618\n",
      "epoch: %d 59\n",
      "129.53973007202148\n",
      "epoch: %d 60\n",
      "Training accuracy: 0.984\n",
      "Test accuracy: 0.960\n",
      "128.98335886001587\n",
      "epoch: %d 61\n",
      "127.38495302200317\n",
      "epoch: %d 62\n",
      "128.4586639404297\n",
      "epoch: %d 63\n",
      "127.20655822753906\n",
      "epoch: %d 64\n",
      "128.19446778297424\n",
      "epoch: %d 65\n",
      "129.37829971313477\n",
      "epoch: %d 66\n",
      "129.03629207611084\n",
      "epoch: %d 67\n",
      "129.18245768547058\n",
      "epoch: %d 68\n",
      "130.2370765209198\n",
      "epoch: %d 69\n",
      "128.85978865623474\n",
      "epoch: %d 70\n",
      "128.48465657234192\n",
      "epoch: %d 71\n",
      "128.10293054580688\n",
      "epoch: %d 72\n",
      "128.7677767276764\n",
      "epoch: %d 73\n",
      "127.77028632164001\n",
      "epoch: %d 74\n",
      "127.87180161476135\n",
      "epoch: %d 75\n",
      "128.4150743484497\n",
      "epoch: %d 76\n",
      "127.91376209259033\n",
      "epoch: %d 77\n",
      "128.6297881603241\n",
      "epoch: %d 78\n",
      "127.32127475738525\n",
      "epoch: %d 79\n",
      "Training accuracy: 0.985\n",
      "Test accuracy: 0.960\n",
      "fc1.weight torch.Size([96, 784])\n",
      "fc2.weight torch.Size([96, 96])\n",
      "fc3.weight torch.Size([10, 96])\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 28 * 28 * 1\n",
    "nb_hidden  = 96\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 512\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "loss_hists = []\n",
    "for i in range(1):\n",
    "    #load dataset\n",
    "    net = SpikingDenseNet(input_size=nb_inputs, nb_steps=nb_steps, num_output=nb_outputs, num_h=nb_hidden).float().to(device)\n",
    "    \n",
    "    train_data = SpikingMNISTDataset(x_train, y_train, nb_steps)\n",
    "    test_data = SpikingMNISTDataset(x_test, y_test, nb_steps)\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    lr = 1e-3\n",
    "    name = 'MNIST'\n",
    "    loss_hist = train(trainloader, testloader, net, lr=lr, nb_epochs=80)\n",
    "    print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(trainloader, net, \"train\")))\n",
    "    print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(testloader, net, name)))\n",
    "    loss_hists.append(loss_hist)\n",
    "    f = open('weight_QAT_' + name + '.npy', 'wb')\n",
    "    for name, param in net.named_parameters():\n",
    "        print(name, param.shape)\n",
    "        np.save(f, param.detach().cpu().numpy())\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-pixel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-bruce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
